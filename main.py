# -*- coding: utf-8 -*-
"""Untitled13.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17aQQs4Z-EobIear2NmlHxxVKqQBS9_XX
"""

import os
import argparse
import requests
import pandas as pd
import pandas_ta as ta
from textblob import TextBlob
import datetime
import time  # For API rate limiting
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Fetch API keys from environment variables
polygon_api_key = os.getenv("POLYGON_API_KEY")
news_api_key = os.getenv("NEWS_API_KEY")

if not polygon_api_key or not news_api_key:
    raise ValueError("API keys are not set. Please set POLYGON_API_KEY and NEWS_API_KEY in the environment.")

# Helper function to fetch historical stock data using Polygon.io
def fetch_stock_data(ticker):
    """Fetch historical stock data for the last 3 months."""
    end_date = datetime.datetime.now().strftime('%Y-%m-%d')
    start_date = (datetime.datetime.now() - datetime.timedelta(days=90)).strftime('%Y-%m-%d')

    url = f"https://api.polygon.io/v2/aggs/ticker/{ticker}/range/1/day/{start_date}/{end_date}?apiKey={polygon_api_key}"

    response = requests.get(url)
    data = response.json()

    if response.status_code != 200 or "results" not in data:
        print(f"Failed to fetch stock data for {ticker}. Error: {data.get('error', 'Unknown error')}")
        return pd.DataFrame()

    # Convert the results into a DataFrame
    df = pd.DataFrame(data["results"])
    df['date'] = pd.to_datetime(df['t'], unit='ms')
    df.set_index('date', inplace=True)

    # Rename columns for clarity
    df.rename(columns={'o': 'Open', 'h': 'High', 'l': 'Low', 'c': 'Close', 'v': 'Volume'}, inplace=True)

    # Calculate RSI and RSI MA
    df['RSI'] = ta.rsi(df['Close'], length=14)
    df['RSI_MA'] = df['RSI'].rolling(window=7).mean()

    return df

# Function to fetch news from NewsAPI
def fetch_news_for_date_range(api_key, query, start_date, end_date):
    """Fetch news articles for a given date range."""
    url = f"https://newsapi.org/v2/everything?q={query}&from={start_date}&to={end_date}&sortBy=publishedAt&language=en&apiKey={api_key}"
    response = requests.get(url)
    news_data = response.json()

    if response.status_code != 200:
        print(f"Error fetching news: {news_data.get('message', 'Unknown error')}")
        return []

    return news_data.get('articles', [])

# Sentiment analysis function
def analyze_sentiment(news_articles):
    """Analyze the sentiment of news articles."""
    sentiment_score = 0
    total_articles = len(news_articles)

    if total_articles == 0:
        return 50, 0  # Neutral sentiment if no articles are found

    for article in news_articles:
        content = f"{article.get('title', '')} {article.get('description', '')}"
        sentiment = TextBlob(content).sentiment.polarity
        sentiment_score += sentiment

    average_sentiment = sentiment_score / total_articles
    scaled_sentiment = int((average_sentiment + 1) * 50)  # Scale to 1-100

    return scaled_sentiment, total_articles

# Generate buy/sell recommendation based on RSI and sentiment score
def get_recommendation(rsi, sentiment_score):
    """Get buy/sell recommendation based on RSI and sentiment score."""
    if sentiment_score > 70 and rsi < 30:
        return "Strong Buy"
    elif sentiment_score > 50 and rsi < 50:
        return "Buy"
    elif 40 <= sentiment_score <= 60 and 40 <= rsi <= 60:
        return "Neutral"
    elif sentiment_score < 50 and rsi > 70:
        return "Sell"
    elif sentiment_score < 30 and rsi > 70:
        return "Strong Sell"
    else:
        return "Neutral"

# Generate a comprehensive report
def generate_report(ticker, api_key):
    """Generate a report with stock data and sentiment analysis."""
    stock_data = fetch_stock_data(ticker)

    if stock_data.empty:
        print(f"No data available for {ticker}.")
        return

    last_15_days = stock_data.tail(15).sort_index(ascending=False)

    for date, row in last_15_days.iterrows():
        open_price = row['Open']
        high_price = row['High']
        close_price = row['Close']
        rsi = row['RSI']
        rsi_ma = row['RSI_MA']

        # Define date range for sentiment analysis (7 days before the current date)
        end_date = date.strftime('%Y-%m-%d')
        start_date = (date - datetime.timedelta(days=7)).strftime('%Y-%m-%d')

        # Fetch news articles and analyze sentiment
        news_articles = fetch_news_for_date_range(api_key, ticker, start_date, end_date)
        sentiment_score, total_articles = analyze_sentiment(news_articles)

        # Get recommendation based on sentiment and RSI
        recommendation = get_recommendation(rsi, sentiment_score)

        # Output the report
        print(f"Date: {date.date()}, Open: {open_price:.2f}, High: {high_price:.2f}, Close: {close_price:.2f}, "
              f"RSI: {rsi:.2f}, RSI MA: {rsi_ma:.2f}, Sentiment Score: {sentiment_score}, "
              f"News Count: {total_articles}, Recommendation: {recommendation}")
        time.sleep(1)  # To avoid hitting rate limits

# Main entry point
if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Stock Analysis Tool")
    parser.add_argument("ticker", type=str, help="Ticker symbol of the stock to analyze")

    args = parser.parse_args()
    generate_report(args.ticker, news_api_key)